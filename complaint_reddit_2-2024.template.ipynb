{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add your custom EntityRuler\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06\n"
     ]
    }
   ],
   "source": [
    "#Init Variables for csv names\n",
    "year=\"2024\"\n",
    "# month=\"01\"\n",
    "cwd=os.getcwd()\n",
    "month=os.path.basename(cwd)\n",
    "print(f\"{month}\")\n",
    "\n",
    "special_identifier='_com_air_hea_tra_ban_us_er_yt_red_net' #for csv output\n",
    "\n",
    "services = [\n",
    "    \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "    \"ER\", \"Youtube\", \"Reddit\", \"Netflix\"\n",
    "    # \"Xfinity\", \"Amtrak\", \"Septa\", \"Spirit\", \"American\"\n",
    "]\n",
    "\n",
    "complaint_patterns = [{\"label\": \"SERVICE\", \"pattern\": service} for service in services]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>I need to talk</td>\n",
       "      <td>u/Entire_Wrongdoer_780</td>\n",
       "      <td>https://www.reddit.com/r/mentalhealth/comments...</td>\n",
       "      <td>I need to free myself from this burden that ea...</td>\n",
       "      <td>18vkgs2</td>\n",
       "      <td>1.704067e+09</td>\n",
       "      <td>t5_2qirg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>In the planning stages now</td>\n",
       "      <td>u/Rando-name2023</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>I don't know if things have ever been this bad...</td>\n",
       "      <td>18vkgsw</td>\n",
       "      <td>1.704067e+09</td>\n",
       "      <td>t5_2qpzs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>good girls &lt;3</td>\n",
       "      <td>u/s-exhibitionism</td>\n",
       "      <td>https://www.reddit.com/r/EdgingTalk/comments/1...</td>\n",
       "      <td>\\nyou’re all doing soo well! keep going, keep ...</td>\n",
       "      <td>18vkgv7</td>\n",
       "      <td>1.704067e+09</td>\n",
       "      <td>t5_3a6db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Farrier here, need financial advice</td>\n",
       "      <td>u/PigArmy</td>\n",
       "      <td>https://www.reddit.com/r/Farriers/comments/18v...</td>\n",
       "      <td>Hey Guys/Gals, I’m a farrier in Northeaster Oh...</td>\n",
       "      <td>18vkgvh</td>\n",
       "      <td>1.704067e+09</td>\n",
       "      <td>t5_2zvj3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Sobre A Odisséia de Homero</td>\n",
       "      <td>u/JacquesTimmermans</td>\n",
       "      <td>https://www.reddit.com/r/u_JacquesTimmermans/c...</td>\n",
       "      <td>https://i.redd.it/2mmortupyp9c1.jpeg</td>\n",
       "      <td>18vkgvt</td>\n",
       "      <td>1.704067e+09</td>\n",
       "      <td>t5_91lb9d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date                                title  \\\n",
       "0   1  2023-12-31                       I need to talk   \n",
       "1   1  2023-12-31           In the planning stages now   \n",
       "2   1  2023-12-31                        good girls <3   \n",
       "3   1  2023-12-31  Farrier here, need financial advice   \n",
       "4   1  2023-12-31           Sobre A Odisséia de Homero   \n",
       "\n",
       "                   author                                                url  \\\n",
       "0  u/Entire_Wrongdoer_780  https://www.reddit.com/r/mentalhealth/comments...   \n",
       "1        u/Rando-name2023  https://www.reddit.com/r/SuicideWatch/comments...   \n",
       "2       u/s-exhibitionism  https://www.reddit.com/r/EdgingTalk/comments/1...   \n",
       "3               u/PigArmy  https://www.reddit.com/r/Farriers/comments/18v...   \n",
       "4     u/JacquesTimmermans  https://www.reddit.com/r/u_JacquesTimmermans/c...   \n",
       "\n",
       "                                             content  post_id     timestamp  \\\n",
       "0  I need to free myself from this burden that ea...  18vkgs2  1.704067e+09   \n",
       "1  I don't know if things have ever been this bad...  18vkgsw  1.704067e+09   \n",
       "2  \\nyou’re all doing soo well! keep going, keep ...  18vkgv7  1.704067e+09   \n",
       "3  Hey Guys/Gals, I’m a farrier in Northeaster Oh...  18vkgvh  1.704067e+09   \n",
       "4               https://i.redd.it/2mmortupyp9c1.jpeg  18vkgvt  1.704067e+09   \n",
       "\n",
       "   subreddit  \n",
       "0   t5_2qirg  \n",
       "1   t5_2qpzs  \n",
       "2   t5_3a6db  \n",
       "3   t5_2zvj3  \n",
       "4  t5_91lb9d  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your patterns\n",
    "# complaint_patterns = [\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Comcast\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Airline\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Healthcare\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Trains\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Banks\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"United States\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"ER\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Youtube\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Reddit\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Lunar Coin\"}\n",
    "# ]\n",
    "\n",
    "ruler.add_patterns(complaint_patterns)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(f\"../../FILTERED_SUBMISSIONS_bad/RS_{year}-{month}.csv\", names=[\"id\", \"date\", \"title\", \"author\", \"url\", \"content\", \"post_id\", \"timestamp\", \"subreddit\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 530792\n",
      "Filtered size: 468409\n"
     ]
    }
   ],
   "source": [
    "# services = [\n",
    "#     \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "#     \"ER\", \"Youtube\", \"Reddit\", \"Lunar Coin\"\n",
    "# ]\n",
    "\n",
    "# Build regex pattern for fast searching (case insensitive)\n",
    "pattern = r'|'.join(services)\n",
    "\n",
    "# Filter rows where content mentions any service\n",
    "filtered_df = df[df['content' ].str.contains(pattern, case=False, na=False) |\n",
    "                df['subreddit'].str.contains(pattern, case=False, na=False) ]\n",
    "\n",
    "print(f\"Original size: {len(df)}\")\n",
    "print(f\"Filtered size: {len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Symptoms??</td>\n",
       "      <td>u/astrofoxical</td>\n",
       "      <td>https://www.reddit.com/r/TryingForABaby/commen...</td>\n",
       "      <td>I'm a mom of 1 and currently TTC but I  just n...</td>\n",
       "      <td>1h3q1vy</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2sil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Raincheck</td>\n",
       "      <td>u/MediumBarnacle1438</td>\n",
       "      <td>https://www.reddit.com/r/Unsent_Unread_Unheard...</td>\n",
       "      <td>That was ALWAYS you \\nWhen I saw on unsent thi...</td>\n",
       "      <td>1h3q21s</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_8ltvmn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>I have CPTSD and my new \"trauma\" therapist tri...</td>\n",
       "      <td>u/Far-Illustrator-4008</td>\n",
       "      <td>https://www.reddit.com/r/TalkTherapy/comments/...</td>\n",
       "      <td>I have CPTSD and I’m just a few sessions in (a...</td>\n",
       "      <td>1h3q23r</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_39dpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Will I be hindered from starting the manga fro...</td>\n",
       "      <td>u/Espurrizumi</td>\n",
       "      <td>https://www.reddit.com/r/StardustCrusaders/com...</td>\n",
       "      <td>I am a huge fan of jojos and have been for yea...</td>\n",
       "      <td>1h3q27e</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2tny5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>I don't know how to go forward.</td>\n",
       "      <td>u/DisappointedInMyseIf</td>\n",
       "      <td>https://www.reddit.com/r/BreakUps/comments/1h3...</td>\n",
       "      <td>This is going to be long, I haven't been able ...</td>\n",
       "      <td>1h3q298</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2ra79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date                                              title  \\\n",
       "0   1  2024-11-30                                         Symptoms??   \n",
       "2   1  2024-11-30                                         Raincheck    \n",
       "3   1  2024-11-30  I have CPTSD and my new \"trauma\" therapist tri...   \n",
       "4   1  2024-11-30  Will I be hindered from starting the manga fro...   \n",
       "5   1  2024-11-30                   I don't know how to go forward.    \n",
       "\n",
       "                   author                                                url  \\\n",
       "0          u/astrofoxical  https://www.reddit.com/r/TryingForABaby/commen...   \n",
       "2    u/MediumBarnacle1438  https://www.reddit.com/r/Unsent_Unread_Unheard...   \n",
       "3  u/Far-Illustrator-4008  https://www.reddit.com/r/TalkTherapy/comments/...   \n",
       "4           u/Espurrizumi  https://www.reddit.com/r/StardustCrusaders/com...   \n",
       "5  u/DisappointedInMyseIf  https://www.reddit.com/r/BreakUps/comments/1h3...   \n",
       "\n",
       "                                             content  post_id     timestamp  \\\n",
       "0  I'm a mom of 1 and currently TTC but I  just n...  1h3q1vy  1.733011e+09   \n",
       "2  That was ALWAYS you \\nWhen I saw on unsent thi...  1h3q21s  1.733011e+09   \n",
       "3  I have CPTSD and I’m just a few sessions in (a...  1h3q23r  1.733011e+09   \n",
       "4  I am a huge fan of jojos and have been for yea...  1h3q27e  1.733011e+09   \n",
       "5  This is going to be long, I haven't been able ...  1h3q298  1.733011e+09   \n",
       "\n",
       "   subreddit  \n",
       "0   t5_2sil5  \n",
       "2  t5_8ltvmn  \n",
       "3   t5_39dpu  \n",
       "4   t5_2tny5  \n",
       "5   t5_2ra79  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words = [\"bad\", \"terrible\", \"lazy\", \"worst\", \"awful\", \"scam\", \"horrible\", \"broken\", \"slow\"]\n",
    "\n",
    "pattern_neg = r'|'.join(neg_words)\n",
    "\n",
    "complaint_df = filtered_df[\n",
    "    filtered_df['content'].str.contains(pattern_neg, case=False, na=False)\n",
    "]\n",
    "\n",
    "complaint_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 435182 entries, 0 to 530791\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   id         435182 non-null  int64  \n",
      " 1   date       435182 non-null  object \n",
      " 2   title      435181 non-null  object \n",
      " 3   author     435182 non-null  object \n",
      " 4   url        435182 non-null  object \n",
      " 5   content    435182 non-null  object \n",
      " 6   post_id    435182 non-null  object \n",
      " 7   timestamp  435182 non-null  float64\n",
      " 8   subreddit  435182 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 33.2+ MB\n"
     ]
    }
   ],
   "source": [
    "complaint_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eaf3cef24540c5b9c78d98761feadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "max_length = 1000  # Skip posts longer than this\n",
    "skipped_posts = []\n",
    "\n",
    "for start in tqdm(range(0, len(df), batch_size)):\n",
    "    end = start + batch_size\n",
    "    batch = df.iloc[start:end].copy()\n",
    "\n",
    "    # Only keep rows with short enough content\n",
    "    batch = batch[batch['content'].str.len() < max_length]\n",
    "\n",
    "    texts = batch['content'].tolist()\n",
    "    ner_results = []\n",
    "\n",
    "    for doc, row in zip(nlp.pipe(texts, batch_size=50), batch.itertuples()):\n",
    "        try:\n",
    "            ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping post {row.post_id} due to error: {e}\")\n",
    "            skipped_posts.append(row.post_id)\n",
    "            ents = []\n",
    "\n",
    "        ner_results.append(ents)\n",
    "\n",
    "    batch['entities'] = ner_results\n",
    "\n",
    "    batch.to_csv(f'ner_results_batch_{year}.{month}_{start}.csv', index=False)\n",
    "\n",
    "# Save skipped post IDs\n",
    "pd.Series(skipped_posts).to_csv('skipped_posts.csv', index=False)\n",
    "\n",
    "print(\"NER complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Load all batch files\n",
    "files = glob.glob(\"ner_results_batch_*.csv\")\n",
    "\n",
    "dfs = [pd.read_csv(f) for f in files]\n",
    "\n",
    "final_ner_df = pd.concat(dfs, ignore_index=True)\n",
    "final_ner_df.to_csv(f'ner_results_append_sum_{year}.{month}{special_identifier}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>how to rehydrate/ avoid a dehydration headache</td>\n",
       "      <td>u/New-Commercial7532</td>\n",
       "      <td>https://www.reddit.com/r/HydroHomies/comments/...</td>\n",
       "      <td>I feel a headache coming on, and i have to go ...</td>\n",
       "      <td>1d59xy1</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>t5_10288s</td>\n",
       "      <td>[('5ish hours', 'TIME'), ('3', 'CARDINAL')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>This guy I talk to texts me to wish my son a H...</td>\n",
       "      <td>u/youwotm8123456781</td>\n",
       "      <td>https://www.reddit.com/r/casualdating/comments...</td>\n",
       "      <td>I'm talking to this guy for a few weeks, but I...</td>\n",
       "      <td>1d59y5w</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>t5_359pr</td>\n",
       "      <td>[('a few weeks', 'DATE'), ('Crip', 'ORG'), ('B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>Some pretty ladies I've come across while working</td>\n",
       "      <td>u/FreeCrayons</td>\n",
       "      <td>https://www.reddit.com/r/spiders/comments/1d59...</td>\n",
       "      <td>https://www.reddit.com/gallery/1d59ye2</td>\n",
       "      <td>1d59ye2</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>t5_2r1sf</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>I think I fucked up!</td>\n",
       "      <td>u/nativesage19</td>\n",
       "      <td>https://www.reddit.com/r/CreatorsAdvice/commen...</td>\n",
       "      <td>https://www.reddit.com/gallery/1d59yir</td>\n",
       "      <td>1d59yir</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>t5_4xgztn</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>separation anxiety</td>\n",
       "      <td>u/Prestigious-Tie-8906</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/1d59...</td>\n",
       "      <td>I’m 23, my dad was never there for me as a kid...</td>\n",
       "      <td>1d59ykm</td>\n",
       "      <td>1.717200e+09</td>\n",
       "      <td>t5_2qmij</td>\n",
       "      <td>[('23', 'DATE'), ('99%', 'PERCENT')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id        date                                              title  \\\n",
       "0   22  2024-05-31     how to rehydrate/ avoid a dehydration headache   \n",
       "1    1  2024-05-31  This guy I talk to texts me to wish my son a H...   \n",
       "2  250  2024-05-31  Some pretty ladies I've come across while working   \n",
       "3    1  2024-05-31                               I think I fucked up!   \n",
       "4    1  2024-05-31                                separation anxiety    \n",
       "\n",
       "                   author                                                url  \\\n",
       "0    u/New-Commercial7532  https://www.reddit.com/r/HydroHomies/comments/...   \n",
       "1     u/youwotm8123456781  https://www.reddit.com/r/casualdating/comments...   \n",
       "2           u/FreeCrayons  https://www.reddit.com/r/spiders/comments/1d59...   \n",
       "3          u/nativesage19  https://www.reddit.com/r/CreatorsAdvice/commen...   \n",
       "4  u/Prestigious-Tie-8906  https://www.reddit.com/r/Anxiety/comments/1d59...   \n",
       "\n",
       "                                             content  post_id     timestamp  \\\n",
       "0  I feel a headache coming on, and i have to go ...  1d59xy1  1.717200e+09   \n",
       "1  I'm talking to this guy for a few weeks, but I...  1d59y5w  1.717200e+09   \n",
       "2             https://www.reddit.com/gallery/1d59ye2  1d59ye2  1.717200e+09   \n",
       "3             https://www.reddit.com/gallery/1d59yir  1d59yir  1.717200e+09   \n",
       "4  I’m 23, my dad was never there for me as a kid...  1d59ykm  1.717200e+09   \n",
       "\n",
       "   subreddit                                           entities  \n",
       "0  t5_10288s        [('5ish hours', 'TIME'), ('3', 'CARDINAL')]  \n",
       "1   t5_359pr  [('a few weeks', 'DATE'), ('Crip', 'ORG'), ('B...  \n",
       "2   t5_2r1sf                                                 []  \n",
       "3  t5_4xgztn                                                 []  \n",
       "4   t5_2qmij               [('23', 'DATE'), ('99%', 'PERCENT')]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('first', 21825), ('one', 14807), ('2', 13300), ('today', 10193), ('3', 9263), ('two', 8959), ('1', 8610), ('4', 5308), ('5', 5249), ('second', 4887), ('yesterday', 3559), ('10', 3030), ('the day', 2925), ('6', 2692), ('years', 2589), ('English', 2588), ('One', 2437), ('Idk', 2382), ('tomorrow', 2253), ('20', 2215)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "entity_counter = Counter()\n",
    "\n",
    "for entities in final_ner_df['entities']:\n",
    "    ents = ast.literal_eval(entities)\n",
    "    entity_counter.update([e[0] for e in ents])\n",
    "\n",
    "print(entity_counter.most_common(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit\n",
      "t5_2vqun     1715\n",
      "t5_2qjdm     1584\n",
      "t5_33rc6     1555\n",
      "t5_122hf1    1475\n",
      "t5_2rjli     1303\n",
      "t5_2w844     1204\n",
      "t5_3pvrd     1184\n",
      "t5_2xtuc     1095\n",
      "t5_2qpzs      973\n",
      "t5_2vfcm      949\n",
      "t5_7f6cy1     943\n",
      "t5_2qmij      912\n",
      "t5_294odh     906\n",
      "t5_2ranw      756\n",
      "t5_2tkvu      751\n",
      "t5_75flg6     742\n",
      "t5_2qqqf      719\n",
      "t5_2sxk3      664\n",
      "t5_2ra79      663\n",
      "t5_2r749      641\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "subreddit_counter = final_ner_df['subreddit'].value_counts()\n",
    "\n",
    "print(subreddit_counter.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    if isinstance(text, str):\n",
    "        return analyzer.polarity_scores(text)['compound']\n",
    "    return 0.0  # Neutral if empty or NaN\n",
    "\n",
    "final_ner_df['sentiment'] = final_ner_df['content'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ner_df.to_csv(f'ner_results_append_sum_{year}_{month}_sentiment{special_identifier}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SERVICE entities only\n",
    "service_sentiments = []\n",
    "\n",
    "for row in final_ner_df.itertuples():\n",
    "    ents = ast.literal_eval(row.entities)\n",
    "    services = [e[0] for e in ents if e[1] == 'SERVICE']\n",
    "    for service in services:\n",
    "        service_sentiments.append((service, row.sentiment))\n",
    "\n",
    "service_df = pd.DataFrame(service_sentiments, columns=['service', 'sentiment'])\n",
    "\n",
    "service_avg_sentiment = service_df.groupby('service')['sentiment'].mean().sort_values()\n",
    "\n",
    "print(service_avg_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=service_avg_sentiment.values, y=service_avg_sentiment.index)\n",
    "plt.title(\"Average Sentiment by Service (VADER)\")\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Service\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ner_df['date'] = pd.to_datetime(final_ner_df['date'])  # or 'timestamp' column if you used that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_sentiments = []\n",
    "\n",
    "for row in final_ner_df.itertuples():\n",
    "    ents = ast.literal_eval(row.entities)\n",
    "    services = [e[0] for e in ents if e[1] == 'SERVICE']\n",
    "    for service in services:\n",
    "        service_sentiments.append((row.date, service, row.sentiment))\n",
    "\n",
    "service_time_df = pd.DataFrame(service_sentiments, columns=['date', 'service', 'sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample weekly for smoother lines\n",
    "service_time_df = service_time_df.set_index('date')\n",
    "\n",
    "avg_sentiment_time = service_time_df.groupby(['service']).resample('7D').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=avg_sentiment_time,\n",
    "    x='date',\n",
    "    y='sentiment',\n",
    "    hue='service'\n",
    ")\n",
    "\n",
    "plt.title(\"Average VADER Sentiment Over Time by Service\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.legend(title='Service', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_freq = final_ner_df.set_index('date').resample('1D').size().reset_index(name='post_count')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(data=post_freq, x='date', y='post_count')\n",
    "\n",
    "plt.title(\"Number of Reddit Posts Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Post Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
