{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jul\n",
      "[{'label': 'SERVICE', 'pattern': 'Xfinity'}, {'label': 'SERVICE', 'pattern': 'Amtrak'}, {'label': 'SERVICE', 'pattern': 'Septa'}, {'label': 'SERVICE', 'pattern': 'Spirit'}, {'label': 'SERVICE', 'pattern': 'American'}]\n"
     ]
    }
   ],
   "source": [
    "#Init Variables\n",
    "def get_month_name_short(month_number):\n",
    "  months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "  return months[month_number - 1] if 1 <= month_number <= 12 else None\n",
    "    \n",
    "month=\"07\"\n",
    "month_int=int(month)\n",
    "month_for_csv_name = get_month_name_short(month_int)\n",
    "\n",
    "\n",
    "services = [\n",
    "    # \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "    # \"ER\", \"Youtube\", \"Reddit\", \"Netflix\",\n",
    "    \"Xfinity\", \"Amtrak\", \"Septa\", \"Spirit\", \"American\"\n",
    "]\n",
    "\n",
    "complaint_patterns = [{\"label\": \"SERVICE\", \"pattern\": service} for service in services]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Symptoms??</td>\n",
       "      <td>u/astrofoxical</td>\n",
       "      <td>https://www.reddit.com/r/TryingForABaby/commen...</td>\n",
       "      <td>I'm a mom of 1 and currently TTC but I  just n...</td>\n",
       "      <td>1h3q1vy</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2sil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Bed bugs/long story/seeking advice</td>\n",
       "      <td>u/WinMysterious9358</td>\n",
       "      <td>https://www.reddit.com/r/Bedbugs/comments/1h3q...</td>\n",
       "      <td>https://i.redd.it/13dqaca3o44e1.jpeg</td>\n",
       "      <td>1h3q1y6</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2s36j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Raincheck</td>\n",
       "      <td>u/MediumBarnacle1438</td>\n",
       "      <td>https://www.reddit.com/r/Unsent_Unread_Unheard...</td>\n",
       "      <td>That was ALWAYS you \\nWhen I saw on unsent thi...</td>\n",
       "      <td>1h3q21s</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_8ltvmn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>I have CPTSD and my new \"trauma\" therapist tri...</td>\n",
       "      <td>u/Far-Illustrator-4008</td>\n",
       "      <td>https://www.reddit.com/r/TalkTherapy/comments/...</td>\n",
       "      <td>I have CPTSD and I’m just a few sessions in (a...</td>\n",
       "      <td>1h3q23r</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_39dpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Will I be hindered from starting the manga fro...</td>\n",
       "      <td>u/Espurrizumi</td>\n",
       "      <td>https://www.reddit.com/r/StardustCrusaders/com...</td>\n",
       "      <td>I am a huge fan of jojos and have been for yea...</td>\n",
       "      <td>1h3q27e</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2tny5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date                                              title  \\\n",
       "0   1  2024-11-30                                         Symptoms??   \n",
       "1   1  2024-11-30                 Bed bugs/long story/seeking advice   \n",
       "2   1  2024-11-30                                         Raincheck    \n",
       "3   1  2024-11-30  I have CPTSD and my new \"trauma\" therapist tri...   \n",
       "4   1  2024-11-30  Will I be hindered from starting the manga fro...   \n",
       "\n",
       "                   author                                                url  \\\n",
       "0          u/astrofoxical  https://www.reddit.com/r/TryingForABaby/commen...   \n",
       "1     u/WinMysterious9358  https://www.reddit.com/r/Bedbugs/comments/1h3q...   \n",
       "2    u/MediumBarnacle1438  https://www.reddit.com/r/Unsent_Unread_Unheard...   \n",
       "3  u/Far-Illustrator-4008  https://www.reddit.com/r/TalkTherapy/comments/...   \n",
       "4           u/Espurrizumi  https://www.reddit.com/r/StardustCrusaders/com...   \n",
       "\n",
       "                                             content  post_id     timestamp  \\\n",
       "0  I'm a mom of 1 and currently TTC but I  just n...  1h3q1vy  1.733011e+09   \n",
       "1               https://i.redd.it/13dqaca3o44e1.jpeg  1h3q1y6  1.733011e+09   \n",
       "2  That was ALWAYS you \\nWhen I saw on unsent thi...  1h3q21s  1.733011e+09   \n",
       "3  I have CPTSD and I’m just a few sessions in (a...  1h3q23r  1.733011e+09   \n",
       "4  I am a huge fan of jojos and have been for yea...  1h3q27e  1.733011e+09   \n",
       "\n",
       "   subreddit  \n",
       "0   t5_2sil5  \n",
       "1   t5_2s36j  \n",
       "2  t5_8ltvmn  \n",
       "3   t5_39dpu  \n",
       "4   t5_2tny5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add your custom EntityRuler\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "# Your patterns\n",
    "# complaint_patterns = [\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Comcast\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Airline\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Healthcare\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Trains\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Banks\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"United States\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"ER\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Youtube\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Reddit\"},\n",
    "#     {\"label\": \"SERVICE\", \"pattern\": \"Lunar Coin\"}\n",
    "# ]\n",
    "\n",
    "ruler.add_patterns(complaint_patterns)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(f\"../../FILTERED_SUBMISSIONS_bad/RS_2024-{month}.csv\", names=[\"id\", \"date\", \"title\", \"author\", \"url\", \"content\", \"post_id\", \"timestamp\", \"subreddit\"])\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 530792\n",
      "Filtered size: 468409\n"
     ]
    }
   ],
   "source": [
    "# services = [\n",
    "#     \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "#     \"ER\", \"Youtube\", \"Reddit\", \"Lunar Coin\"\n",
    "# ]\n",
    "\n",
    "# Build regex pattern for fast searching (case insensitive)\n",
    "pattern = r'|'.join(services)\n",
    "\n",
    "# Filter rows where content mentions any service\n",
    "filtered_df = df[df['content' ].str.contains(pattern, case=False, na=False) |\n",
    "                df['subreddit'].str.contains(pattern, case=False, na=False) ]\n",
    "\n",
    "print(f\"Original size: {len(df)}\")\n",
    "print(f\"Filtered size: {len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>post_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Symptoms??</td>\n",
       "      <td>u/astrofoxical</td>\n",
       "      <td>https://www.reddit.com/r/TryingForABaby/commen...</td>\n",
       "      <td>I'm a mom of 1 and currently TTC but I  just n...</td>\n",
       "      <td>1h3q1vy</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2sil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Raincheck</td>\n",
       "      <td>u/MediumBarnacle1438</td>\n",
       "      <td>https://www.reddit.com/r/Unsent_Unread_Unheard...</td>\n",
       "      <td>That was ALWAYS you \\nWhen I saw on unsent thi...</td>\n",
       "      <td>1h3q21s</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_8ltvmn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>I have CPTSD and my new \"trauma\" therapist tri...</td>\n",
       "      <td>u/Far-Illustrator-4008</td>\n",
       "      <td>https://www.reddit.com/r/TalkTherapy/comments/...</td>\n",
       "      <td>I have CPTSD and I’m just a few sessions in (a...</td>\n",
       "      <td>1h3q23r</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_39dpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>Will I be hindered from starting the manga fro...</td>\n",
       "      <td>u/Espurrizumi</td>\n",
       "      <td>https://www.reddit.com/r/StardustCrusaders/com...</td>\n",
       "      <td>I am a huge fan of jojos and have been for yea...</td>\n",
       "      <td>1h3q27e</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2tny5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>I don't know how to go forward.</td>\n",
       "      <td>u/DisappointedInMyseIf</td>\n",
       "      <td>https://www.reddit.com/r/BreakUps/comments/1h3...</td>\n",
       "      <td>This is going to be long, I haven't been able ...</td>\n",
       "      <td>1h3q298</td>\n",
       "      <td>1.733011e+09</td>\n",
       "      <td>t5_2ra79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date                                              title  \\\n",
       "0   1  2024-11-30                                         Symptoms??   \n",
       "2   1  2024-11-30                                         Raincheck    \n",
       "3   1  2024-11-30  I have CPTSD and my new \"trauma\" therapist tri...   \n",
       "4   1  2024-11-30  Will I be hindered from starting the manga fro...   \n",
       "5   1  2024-11-30                   I don't know how to go forward.    \n",
       "\n",
       "                   author                                                url  \\\n",
       "0          u/astrofoxical  https://www.reddit.com/r/TryingForABaby/commen...   \n",
       "2    u/MediumBarnacle1438  https://www.reddit.com/r/Unsent_Unread_Unheard...   \n",
       "3  u/Far-Illustrator-4008  https://www.reddit.com/r/TalkTherapy/comments/...   \n",
       "4           u/Espurrizumi  https://www.reddit.com/r/StardustCrusaders/com...   \n",
       "5  u/DisappointedInMyseIf  https://www.reddit.com/r/BreakUps/comments/1h3...   \n",
       "\n",
       "                                             content  post_id     timestamp  \\\n",
       "0  I'm a mom of 1 and currently TTC but I  just n...  1h3q1vy  1.733011e+09   \n",
       "2  That was ALWAYS you \\nWhen I saw on unsent thi...  1h3q21s  1.733011e+09   \n",
       "3  I have CPTSD and I’m just a few sessions in (a...  1h3q23r  1.733011e+09   \n",
       "4  I am a huge fan of jojos and have been for yea...  1h3q27e  1.733011e+09   \n",
       "5  This is going to be long, I haven't been able ...  1h3q298  1.733011e+09   \n",
       "\n",
       "   subreddit  \n",
       "0   t5_2sil5  \n",
       "2  t5_8ltvmn  \n",
       "3   t5_39dpu  \n",
       "4   t5_2tny5  \n",
       "5   t5_2ra79  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_words = [\"bad\", \"terrible\", \"lazy\", \"worst\", \"awful\", \"scam\", \"horrible\", \"broken\", \"slow\"]\n",
    "\n",
    "pattern_neg = r'|'.join(neg_words)\n",
    "\n",
    "complaint_df = filtered_df[\n",
    "    filtered_df['content'].str.contains(pattern_neg, case=False, na=False)\n",
    "]\n",
    "\n",
    "complaint_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 435182 entries, 0 to 530791\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   id         435182 non-null  int64  \n",
      " 1   date       435182 non-null  object \n",
      " 2   title      435181 non-null  object \n",
      " 3   author     435182 non-null  object \n",
      " 4   url        435182 non-null  object \n",
      " 5   content    435182 non-null  object \n",
      " 6   post_id    435182 non-null  object \n",
      " 7   timestamp  435182 non-null  float64\n",
      " 8   subreddit  435182 non-null  object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 33.2+ MB\n"
     ]
    }
   ],
   "source": [
    "complaint_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eaf3cef24540c5b9c78d98761feadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "max_length = 1000  # Skip posts longer than this\n",
    "skipped_posts = []\n",
    "\n",
    "for start in tqdm(range(0, len(df), batch_size)):\n",
    "    end = start + batch_size\n",
    "    batch = df.iloc[start:end].copy()\n",
    "\n",
    "    # Only keep rows with short enough content\n",
    "    batch = batch[batch['content'].str.len() < max_length]\n",
    "\n",
    "    texts = batch['content'].tolist()\n",
    "    ner_results = []\n",
    "\n",
    "    for doc, row in zip(nlp.pipe(texts, batch_size=50), batch.itertuples()):\n",
    "        try:\n",
    "            ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping post {row.post_id} due to error: {e}\")\n",
    "            skipped_posts.append(row.post_id)\n",
    "            ents = []\n",
    "\n",
    "        ner_results.append(ents)\n",
    "\n",
    "    batch['entities'] = ner_results\n",
    "\n",
    "    batch.to_csv(f'ner_results_batch_{month_for_csv_name}_{start}.csv', index=False)\n",
    "\n",
    "# Save skipped post IDs\n",
    "pd.Series(skipped_posts).to_csv('skipped_posts.csv', index=False)\n",
    "\n",
    "print(\"NER complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Load all batch files\n",
    "files = glob.glob(\"ner_results_batch_*.csv\")\n",
    "\n",
    "dfs = [pd.read_csv(f) for f in files]\n",
    "\n",
    "final_ner_df = pd.concat(dfs, ignore_index=True)\n",
    "final_ner_df.to_csv('ner_results_full.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "entity_counter = Counter()\n",
    "\n",
    "for entities in final_ner_df['entities']:\n",
    "    ents = ast.literal_eval(entities)\n",
    "    entity_counter.update([e[0] for e in ents])\n",
    "\n",
    "print(entity_counter.most_common(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_counter = final_ner_df['subreddit'].value_counts()\n",
    "\n",
    "print(subreddit_counter.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    if isinstance(text, str):\n",
    "        return analyzer.polarity_scores(text)['compound']\n",
    "    return 0.0  # Neutral if empty or NaN\n",
    "\n",
    "final_ner_df['sentiment'] = final_ner_df['content'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SERVICE entities only\n",
    "service_sentiments = []\n",
    "\n",
    "for row in final_ner_df.itertuples():\n",
    "    ents = ast.literal_eval(row.entities)\n",
    "    services = [e[0] for e in ents if e[1] == 'SERVICE']\n",
    "    for service in services:\n",
    "        service_sentiments.append((service, row.sentiment))\n",
    "\n",
    "service_df = pd.DataFrame(service_sentiments, columns=['service', 'sentiment'])\n",
    "\n",
    "service_avg_sentiment = service_df.groupby('service')['sentiment'].mean().sort_values()\n",
    "\n",
    "print(service_avg_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=service_avg_sentiment.values, y=service_avg_sentiment.index)\n",
    "plt.title(\"Average Sentiment by Service (VADER)\")\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Service\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ner_df['date'] = pd.to_datetime(final_ner_df['date'])  # or 'timestamp' column if you used that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_sentiments = []\n",
    "\n",
    "for row in final_ner_df.itertuples():\n",
    "    ents = ast.literal_eval(row.entities)\n",
    "    services = [e[0] for e in ents if e[1] == 'SERVICE']\n",
    "    for service in services:\n",
    "        service_sentiments.append((row.date, service, row.sentiment))\n",
    "\n",
    "service_time_df = pd.DataFrame(service_sentiments, columns=['date', 'service', 'sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample weekly for smoother lines\n",
    "service_time_df = service_time_df.set_index('date')\n",
    "\n",
    "avg_sentiment_time = service_time_df.groupby(['service']).resample('7D').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=avg_sentiment_time,\n",
    "    x='date',\n",
    "    y='sentiment',\n",
    "    hue='service'\n",
    ")\n",
    "\n",
    "plt.title(\"Average VADER Sentiment Over Time by Service\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.legend(title='Service', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_freq = final_ner_df.set_index('date').resample('1D').size().reset_index(name='post_count')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(data=post_freq, x='date', y='post_count')\n",
    "\n",
    "plt.title(\"Number of Reddit Posts Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Post Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
