{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "import ast\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy version: 3.8.5\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "#spacy definitions\n",
    "import spacy\n",
    "print(f\"spaCy version: {spacy.__version__}\")\n",
    "print(f\"CUDA available: {spacy.prefer_gpu()}\")\n",
    "# print(f\"GPU device count: {spacy.util.get_gpu_count()}\")\n",
    "\n",
    "# Load spaCy model\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Add your custom EntityRuler\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init Variables for csv names\n",
    "year=\"2024\"\n",
    "# month=\"01\"\n",
    "cwd=os.getcwd()\n",
    "month=os.path.basename(cwd)\n",
    "# print(f\"{month}\")\n",
    "\n",
    "#special_identifier='_xfin_amt_sep_spi_ama'\n",
    "special_identifier='_MULTI_PLOT' #for csv output\n",
    "# Construct the directory name\n",
    "output_directory = f\"batch{special_identifier}\"\n",
    "\n",
    "services = [\n",
    "    \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "    \"ER\", \"Youtube\", \"Reddit\", \"Netflix\",\n",
    "    \"Xfinity\", \"Amtrak\", \"Septa\", \"Spirit\", \"American\",\n",
    "    \"Disney\"\n",
    "]\n",
    "\n",
    "complaint_patterns = [{\"label\": \"SERVICE\", \"pattern\": service} for service in services]\n",
    "ruler.add_patterns(complaint_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 .parquet files in PARQUET/batch_MULTI_PLOT\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_12_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_09_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_11_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_01_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_02_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_03_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_04_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_05_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_06_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_07_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_08_sentiment_MULTI_PLOT.parquet\n",
      "Reading file: PARQUET/batch_MULTI_PLOT/ner_results_append_sum2024_10_sentiment_MULTI_PLOT.parquet\n",
      "Concatenating DataFrames...\n",
      "Concatenation complete.\n",
      "Combined DataFrame shape: (3595301, 11)\n",
      "   id        date                                              title  \\\n",
      "0   1  2024-11-30                 Bed bugs/long story/seeking advice   \n",
      "1   1  2024-11-30  Will I be hindered from starting the manga fro...   \n",
      "2  35  2024-11-30  Do yâ€™all think Jess or Emily would win in a ph...   \n",
      "3  31  2024-11-30                                    Mau5 b2b Andy C   \n",
      "4   2  2024-11-30                          Sick mid training block?    \n",
      "\n",
      "                 author                                                url  \\\n",
      "0   u/WinMysterious9358  https://www.reddit.com/r/Bedbugs/comments/1h3q...   \n",
      "1         u/Espurrizumi  https://www.reddit.com/r/StardustCrusaders/com...   \n",
      "2  u/Dry-Pineapple-3313  https://www.reddit.com/r/untildawn/comments/1h...   \n",
      "3    u/strangeBehavior7  https://www.reddit.com/r/deadmau5/comments/1h3...   \n",
      "4    u/FluffyDebate5125  https://www.reddit.com/r/Marathon_Training/com...   \n",
      "\n",
      "                                             content  post_id     timestamp  \\\n",
      "0               https://i.redd.it/13dqaca3o44e1.jpeg  1h3q1y6  1.733011e+09   \n",
      "1  I am a huge fan of jojos and have been for yea...  1h3q27e  1.733011e+09   \n",
      "2  I think Emily cause we see her more capable of...  1h3q2ao  1.733011e+09   \n",
      "3                    https://v.redd.it/zuf6elt2o44e1  1h3q2ik  1.733011e+09   \n",
      "4  Got sick -- nothing serious, mainly just head ...  1h3q2lh  1.733011e+09   \n",
      "\n",
      "  subreddit                                           entities  sentiment  \n",
      "0  t5_2s36j                                                 []     0.0000  \n",
      "1  t5_2tny5             [('years', 'DATE'), ('7', 'CARDINAL')]    -0.4443  \n",
      "2  t5_2xlrw           [('Jessica', 'ORG'), ('Jess', 'PERSON')]    -0.7688  \n",
      "3  t5_2ru8s                                                 []     0.0000  \n",
      "4  t5_31lup  [('week 8', 'DATE'), ('an 18 mile', 'QUANTITY'...     0.1660  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "parquet_directory = f\"PARQUET/batch{special_identifier}\"\n",
    "plot_output_directory = f\"YEAR_APPEND/batch{special_identifier}/PLOTS\"\n",
    "\n",
    "# --- Read and Concatenate Parquet Files ---\n",
    "all_parquet_files = []\n",
    "try:\n",
    "    # Use glob to find all files ending with .parquet in the specified directory\n",
    "    parquet_file_pattern = os.path.join(parquet_directory, \"ner*.parquet\")\n",
    "    all_parquet_files = glob.glob(parquet_file_pattern)\n",
    "\n",
    "    if not all_parquet_files:\n",
    "        print(f\"No .parquet files found in directory: {parquet_directory}\")\n",
    "    else:\n",
    "        print(f\"Found {len(all_parquet_files)} .parquet files in {parquet_directory}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error finding parquet files: {e}\")\n",
    "    # You might want to exit or handle this error differently\n",
    "    exit() # Exit the script if we can't find files\n",
    "\n",
    "# List to hold DataFrames read from each file\n",
    "dfs = []\n",
    "\n",
    "# Read each parquet file and append to the list\n",
    "for f in all_parquet_files:\n",
    "    try:\n",
    "        print(f\"Reading file: {f}\")\n",
    "        df = pd.read_parquet(f)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading parquet file {f}: {e}\")\n",
    "        # Decide whether to skip the file or stop processing\n",
    "        continue # Skip this file and try the next one\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.DataFrame() # Initialize an empty DataFrame\n",
    "if dfs: # Check if the list of DataFrames is not empty\n",
    "    try:\n",
    "        print(\"Concatenating DataFrames...\")\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        print(\"Concatenation complete.\")\n",
    "        print(f\"Combined DataFrame shape: {combined_df.shape}\")\n",
    "        # print(combined_df.head()) # Display the head of the combined DataFrame\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error concatenating DataFrames: {e}\")\n",
    "else:\n",
    "    print(\"No DataFrames were loaded to concatenate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combined_final_parquet = f'APPEND_SUM_{year}_sentiment{special_identifier}.parquet'\n",
    "# combined_df.to_parquet(os.path.join(parquet_directory, combined_final_parquet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'title', 'author', 'url', 'content', 'post_id',\n",
       "       'timestamp', 'subreddit', 'entities', 'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PLOTS directory if it doesn't exist\n",
    "\n",
    "# combined_final_parquet = f'APPEND_SUM_{year}_sentiment{special_identifier}.parquet'\n",
    "# combined_df = pd.read_parquet(os.path.join(parquet_directory, combined_final_parquet))\n",
    "\n",
    "os.makedirs(plot_output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520ac0fe4a3e444da07dae30002685c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Plotting Data:   0%|          | 0/3595301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aded74ac2a444995a8b3ac506853597c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Monthly Plots:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-plot figure saved to: YEAR_APPEND/batch_MULTI_PLOT/PLOTS/sentiment_by_month_daily_avg_12plots.png\n"
     ]
    }
   ],
   "source": [
    "#Plot 12 plots, monthly, all entities\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import os\n",
    "import calendar # To get month names\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np # Import NumPy\n",
    "\n",
    "# Assuming combined_df is already loaded with necessary columns (timestamp, entities, sentiment)\n",
    "# Assuming 'services' and 'plot_output_directory' are defined\n",
    "\n",
    "# --- Configuration ---\n",
    "# Assuming your DataFrame is named 'combined_df' and has the specified columns:\n",
    "# id, date, title, author, url, content, post_id, timestamp, subreddit, entities, sentiment\n",
    "# Assuming 'services' and 'plot_output_directory' are defined.\n",
    "\n",
    "# Example definitions if they are not defined elsewhere:\n",
    "# services = [\n",
    "#     \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "#     \"ER\", \"Youtube\", \"Reddit\", \"Netflix\",\n",
    "#     \"Xfinity\", \"Amtrak\", \"Septa\", \"Spirit\", \"American\",\n",
    "#     \"Disney\"\n",
    "# ]\n",
    "\n",
    "# Define your plot output directory\n",
    "# special_identifier = \"_your_identifier\" # Example, replace with your value\n",
    "# plot_output_directory = f\"batch{special_identifier}/PLOTS\"\n",
    "# os.makedirs(plot_output_directory, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "\n",
    "# --- Extract relevant data and calculate daily average sentiment ---\n",
    "entity_sentiments_over_time = []\n",
    "\n",
    "# Assuming 'combined_df' is your DataFrame with columns:\n",
    "# id, date, title, author, url, content, post_id, timestamp, subreddit, entities, sentiment\n",
    "\n",
    "# Wrap the iteration over DataFrame rows with tqdm, using combined_df\n",
    "for index, row in tqdm(combined_df.iterrows(), total=len(combined_df), desc=\"Extracting Plotting Data\"):\n",
    "    try:\n",
    "        entities_value = row['entities']\n",
    "        # Handle empty, NaN, or invalid entities\n",
    "        if pd.isna(entities_value) or entities_value is None or str(entities_value).strip() == \"\":\n",
    "            ents = []\n",
    "        else:\n",
    "            entities_str = str(entities_value)\n",
    "            try:\n",
    "                ents = ast.literal_eval(entities_str)\n",
    "                if not isinstance(ents, list):\n",
    "                     print(f\"Warning: ast.literal_eval did not return a list for row {index}. Result type: {type(ents)}. Value: {entities_value}\")\n",
    "                     ents = []\n",
    "            except (SyntaxError, ValueError, Exception) as e:\n",
    "                print(f\"Error evaluating entities string for row {index}: {e}. Value: {entities_value}\")\n",
    "                ents = []\n",
    "\n",
    "        # Convert timestamp to datetime and then extract date\n",
    "        # Assuming 'timestamp' is a timestamp (integer or float)\n",
    "        if pd.isna(row['timestamp']) or row['timestamp'] is None:\n",
    "            post_date = None # Handle missing timestamp\n",
    "        else:\n",
    "            try:\n",
    "                # Attempt to convert to numeric first for robustness before datetime conversion\n",
    "                timestamp_numeric = pd.to_numeric(row['timestamp'], errors='coerce')\n",
    "                if not pd.isna(timestamp_numeric):\n",
    "                    post_date = pd.to_datetime(timestamp_numeric, unit='s').date() # Adjust unit if needed\n",
    "                else:\n",
    "                    print(f\"Warning: Could not convert timestamp to numeric for row {index}: {row['timestamp']}\")\n",
    "                    post_date = None\n",
    "            except (ValueError, TypeError) as e:\n",
    "                 print(f\"Error converting timestamp {row['timestamp']} on row {index}: {e}\")\n",
    "                 post_date = None # Handle invalid timestamp\n",
    "\n",
    "\n",
    "        sentiment = row['sentiment'] # Assuming sentiment is already a number or NaN\n",
    "\n",
    "        if post_date is not None: # Only process if date is valid\n",
    "             for ent_text, ent_label in ents:\n",
    "                 if isinstance(ent_text, str) and isinstance(ent_label, str) and ent_label == 'SERVICE' and ent_text in services:\n",
    "                    if np.isreal(sentiment): # Corrected: Use np.isreal\n",
    "                        entity_sentiments_over_time.append((ent_text, post_date, float(sentiment))) # Ensure sentiment is float\n",
    "                    else:\n",
    "                         print(f\"Warning: Skipping non-numeric sentiment {sentiment} for row {index}.\")\n",
    "\n",
    "\n",
    "    except (KeyError, TypeError, Exception) as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "entity_sentiment_df = pd.DataFrame(entity_sentiments_over_time, columns=['service', 'date', 'sentiment'])\n",
    "\n",
    "# Convert the 'date' column to datetime objects and extract month and day\n",
    "if not entity_sentiment_df.empty:\n",
    "    # Assuming 'date' column in combined_df is already in a format parsable by pd.to_datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(entity_sentiment_df['date']):\n",
    "         try:\n",
    "             entity_sentiment_df['date'] = pd.to_datetime(entity_sentiment_df['date'])\n",
    "         except ValueError as e:\n",
    "              print(f\"Error converting 'date' column to datetime: {e}\")\n",
    "              print(\"Please ensure the 'date' column is in a recognizable format.\")\n",
    "              entity_sentiment_df = pd.DataFrame() # Clear if date conversion fails\n",
    "\n",
    "if not entity_sentiment_df.empty:\n",
    "    entity_sentiment_df['month'] = entity_sentiment_df['date'].dt.month\n",
    "    entity_sentiment_df['day'] = entity_sentiment_df['date'].dt.day\n",
    "\n",
    "    # Calculate daily average sentiment\n",
    "    # We need to group by service, month, and day to get daily average within each month\n",
    "    if all(col in entity_sentiment_df.columns for col in ['service', 'month', 'day', 'sentiment']):\n",
    "         avg_sentiment_per_day_month = entity_sentiment_df.groupby(['service', 'month', 'day'])['sentiment'].mean().reset_index()\n",
    "    else:\n",
    "         print(\"Required columns for grouping ('service', 'month', 'day', 'sentiment') not found after extraction.\")\n",
    "         avg_sentiment_per_day_month = pd.DataFrame() # Ensure it's an empty DataFrame\n",
    "\n",
    "\n",
    "    # --- Plotting 12 Plots by Month ---\n",
    "    if not avg_sentiment_per_day_month.empty: # Only attempt plotting if aggregation was successful\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(18, 16), sharey=True) # Create a 4x3 grid of subplots\n",
    "        fig.suptitle(\"Average Daily Sentiment per Service by Month (All Years Combined)\", fontsize=16, y=1.02) # Main title for the figure\n",
    "\n",
    "        # Flatten the 2D axes array for easy iteration\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # Create a color cycle that will be consistent across services in all plots\n",
    "        colors = cycle(plt.cm.tab10.colors)\n",
    "\n",
    "        # Wrap the loop iterating through months with tqdm\n",
    "        for month_num in tqdm(range(1, 13), desc=\"Generating Monthly Plots\"): # Iterate through months 1 to 12 with tqdm\n",
    "            ax = axes[month_num - 1] # Get the correct subplot axes for the current month (0-indexed)\n",
    "            month_name = calendar.month_name[month_num] # Get the month name (e.g., 'January')\n",
    "\n",
    "            # Filter data for the current month\n",
    "            # .copy() is used to avoid SettingWithCopyWarning\n",
    "            monthly_data = avg_sentiment_per_day_month[avg_sentiment_per_day_month['month'] == month_num].copy()\n",
    "\n",
    "            if not monthly_data.empty:\n",
    "                 # Create a fresh color cycle for each month's plot\n",
    "                 month_colors = cycle(plt.cm.tab10.colors)\n",
    "                 for service in services: # Iterate through each service\n",
    "                     # Filter data for the current service within the current month\n",
    "                     service_monthly_data = monthly_data[monthly_data['service'] == service]\n",
    "                     if not service_monthly_data.empty:\n",
    "                         color = next(month_colors) # Get the color for this service\n",
    "                         # Plot day of the month vs. daily average sentiment\n",
    "                         ax.plot(\n",
    "                             service_monthly_data['day'],\n",
    "                             service_monthly_data['sentiment'],\n",
    "                             label=service, # Label for the legend\n",
    "                             color=color,\n",
    "                             marker='o', # Use markers for clarity on daily data points\n",
    "                             linestyle='-' # Use a line to connect daily points\n",
    "                         )\n",
    "\n",
    "            # --- Format the subplot for the current month ---\n",
    "            ax.set_title(month_name) # Set the title for the current month's subplot\n",
    "            # Only add y-label to the leftmost plots for clarity\n",
    "            if month_num in [1, 4, 7, 10]: # Months in the first column\n",
    "                 ax.set_ylabel(\"Avg Sentiment\")\n",
    "            ax.grid(True) # Add a grid to the subplot\n",
    "            ax.set_xticks(range(0, 32, 5)) # Set x-ticks for days (e.g., 0, 5, 10, ..., 30)\n",
    "            ax.set_xlim(0, 31) # Set x-axis limits from day 0 to 31\n",
    "\n",
    "            # Only add x-label to the bottommost plots\n",
    "            if month_num in [10, 11, 12]: # Months in the last row\n",
    "                ax.set_xlabel(\"Day of Month\")\n",
    "            else:\n",
    "                 # Hide x-axis labels for plots not in the bottom row\n",
    "                 ax.tick_params(labelbottom=False)\n",
    "\n",
    "\n",
    "        # --- Add a single legend for all subplots outside the figure ---\n",
    "        # We need handles and labels for the legend. Since colors are cycled per month,\n",
    "        # we create dummy handles to represent each service with a consistent color\n",
    "        # from the colormap's cycle.\n",
    "        dummy_colors = cycle(plt.cm.tab10.colors)\n",
    "        dummy_handles = [plt.Line2D([0], [0], color=next(dummy_colors), lw=2) for _ in services]\n",
    "        # Place the legend on the right side of the figure\n",
    "        fig.legend(dummy_handles, services, title=\"Entity\", bbox_to_anchor=(1.02, 0.5), loc='center left', borderaxespad=0.)\n",
    "\n",
    "\n",
    "        # --- Adjust layout ---\n",
    "        # Use tight_layout to automatically adjust subplot parameters for a tight layout\n",
    "        # rect parameter is used to leave space for the suptitle and the outside legend\n",
    "        plt.tight_layout(rect=[0, 0.03, 0.95, 0.98])\n",
    "\n",
    "\n",
    "        # --- Save the entire figure ---\n",
    "        # Ensure plot_output_directory is defined and exists before saving\n",
    "        # Example check: if 'plot_output_directory' in locals() and os.path.exists(plot_output_directory):\n",
    "                \n",
    "        plot_filename = os.path.join(plot_output_directory, \"sentiment_by_month_daily_avg_12plots.png\")\n",
    "        plt.savefig(plot_filename)\n",
    "        plt.close(fig) # Close the figure to prevent display if running in batch\n",
    "\n",
    "        print(f\"12-plot figure saved to: {plot_filename}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Average daily sentiment DataFrame is empty after aggregation. No plots generated.\")\n",
    "\n",
    "else:\n",
    "    print(\"Post sentiment DataFrame is empty after initial processing. No plots or aggregations performed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68f746ff24e447694b0cb7fe5e1b0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Plotting Data:   0%|          | 0/3595301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234efc9a3a7044aa956fbd97b1aab85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plotting Volatility Levels:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee81b23128e4d2297123ca483ec27e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Plotting High Volatility:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc42649355214670af1ff6997499c1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Plotting Medium Volatility:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db07e204a8214e9b83ab8848df0592fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Plotting Low Volatility:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x12 grid plot saved to: YEAR_APPEND/batch_MULTI_PLOT/PLOTS/sentiment_volatility_month_grid.png\n"
     ]
    }
   ],
   "source": [
    "# #36 plots, monthly plots with sub plotting via voltatilty\n",
    "# import pandas as pd\n",
    "# import ast\n",
    "# import matplotlib.pyplot as plt\n",
    "# from itertools import cycle\n",
    "# import os\n",
    "# import calendar # To get month names\n",
    "# from tqdm.notebook import tqdm\n",
    "# import numpy as np # Import NumPy\n",
    "\n",
    "# # Assuming combined_df is already loaded with necessary columns (timestamp, entities, sentiment)\n",
    "# # Assuming 'services' and 'plot_output_directory' are defined\n",
    "\n",
    "# # --- Configuration ---\n",
    "# # Assuming your DataFrame is named 'combined_df' and has the specified columns.\n",
    "# # Assuming 'services' and 'plot_output_directory' are defined.\n",
    "\n",
    "# # Example definitions if they are not defined elsewhere:\n",
    "# # services = [\n",
    "# #     \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "# #     \"ER\", \"Youtube\", \"Reddit\", \"Netflix\",\n",
    "# #     \"Xfinity\", \"Amtrak\", \"Septa\", \"Spirit\", \"American\",\n",
    "# #     \"Disney\"\n",
    "# # ]\n",
    "\n",
    "# # Define your plot output directory\n",
    "# # special_identifier = \"_your_identifier\" # Example, replace with your value\n",
    "# # plot_output_directory = f\"batch{special_identifier}/PLOTS\"\n",
    "# # os.makedirs(plot_output_directory, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "\n",
    "# # --- Extract relevant data and calculate daily average sentiment ---\n",
    "# entity_sentiments_over_time = []\n",
    "\n",
    "# # Assuming combined_df has: timestamp, entities, sentiment\n",
    "# for index, row in tqdm(combined_df.iterrows(), total=len(combined_df), desc=\"Extracting Plotting Data\"):\n",
    "#     try:\n",
    "#         entities_value = row['entities']\n",
    "#         # Handle empty, NaN, or invalid entities\n",
    "#         if pd.isna(entities_value) or entities_value is None or str(entities_value).strip() == \"\":\n",
    "#             ents = []\n",
    "#         else:\n",
    "#             entities_str = str(entities_value)\n",
    "#             try:\n",
    "#                 ents = ast.literal_eval(entities_str)\n",
    "#                 if not isinstance(ents, list):\n",
    "#                      print(f\"Warning: ast.literal_eval did not return a list for row {index}. Result type: {type(ents)}. Value: {entities_value}\")\n",
    "#                      ents = []\n",
    "#             except (SyntaxError, ValueError, Exception) as e:\n",
    "#                 print(f\"Error evaluating entities string for row {index}: {e}. Value: {entities_value}\")\n",
    "#                 ents = []\n",
    "\n",
    "#         # Convert timestamp to datetime and then extract date\n",
    "#         # Assuming 'timestamp' is a timestamp (integer or float)\n",
    "#         if pd.isna(row['timestamp']) or row['timestamp'] is None:\n",
    "#             post_date = None # Handle missing timestamp\n",
    "#         else:\n",
    "#             try:\n",
    "#                 timestamp_numeric = pd.to_numeric(row['timestamp'], errors='coerce')\n",
    "#                 if not pd.isna(timestamp_numeric):\n",
    "#                     post_date = pd.to_datetime(timestamp_numeric, unit='s').date() # Adjust unit if needed\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Could not convert timestamp to numeric for row {index}: {row['timestamp']}\")\n",
    "#                     post_date = None\n",
    "#             except (ValueError, TypeError) as e:\n",
    "#                  print(f\"Error converting timestamp {row['timestamp']} on row {index}: {e}\")\n",
    "#                  post_date = None # Handle invalid timestamp\n",
    "\n",
    "\n",
    "#         sentiment = row['sentiment'] # Assuming sentiment is already a number or NaN\n",
    "\n",
    "#         if post_date is not None: # Only process if date is valid\n",
    "#              for ent_text, ent_label in ents:\n",
    "#                  if isinstance(ent_text, str) and isinstance(ent_label, str) and ent_label == 'SERVICE' and ent_text in services:\n",
    "#                     if np.isreal(sentiment): # Corrected: Use np.isreal\n",
    "#                         entity_sentiments_over_time.append((ent_text, post_date, float(sentiment))) # Ensure sentiment is float\n",
    "#                     else:\n",
    "#                          print(f\"Warning: Skipping non-numeric sentiment {sentiment} for row {index}.\")\n",
    "\n",
    "\n",
    "#     except (KeyError, TypeError, Exception) as e:\n",
    "#         print(f\"Error processing row {index}: {e}\")\n",
    "#         continue\n",
    "\n",
    "\n",
    "# # Create a DataFrame from the extracted data\n",
    "# entity_sentiment_df = pd.DataFrame(entity_sentiments_over_time, columns=['service', 'date', 'sentiment'])\n",
    "\n",
    "# # Convert the 'date' column to datetime objects and extract month and day\n",
    "# if not entity_sentiment_df.empty:\n",
    "#     if not pd.api.types.is_datetime64_any_dtype(entity_sentiment_df['date']):\n",
    "#          try:\n",
    "#              entity_sentiment_df['date'] = pd.to_datetime(entity_sentiment_df['date'])\n",
    "#          except ValueError as e:\n",
    "#               print(f\"Error converting 'date' column to datetime: {e}\")\n",
    "#               print(\"Please ensure the 'date' column is in a recognizable format.\")\n",
    "#               entity_sentiment_df = pd.DataFrame() # Clear if date conversion fails\n",
    "\n",
    "# if not entity_sentiment_df.empty:\n",
    "#     entity_sentiment_df['month'] = entity_sentiment_df['date'].dt.month\n",
    "#     entity_sentiment_df['day'] = entity_sentiment_df['date'].dt.day\n",
    "\n",
    "#     # Calculate daily average sentiment\n",
    "#     if all(col in entity_sentiment_df.columns for col in ['service', 'month', 'day', 'sentiment']):\n",
    "#          # Group by service, month, and day to get daily average within each month\n",
    "#          avg_sentiment_per_day_month = entity_sentiment_df.groupby(['service', 'month', 'day'])['sentiment'].mean().reset_index()\n",
    "#     else:\n",
    "#          print(\"Required columns for daily average grouping ('service', 'month', 'day', 'sentiment') not found after extraction.\")\n",
    "#          avg_sentiment_per_day_month = pd.DataFrame()\n",
    "\n",
    "\n",
    "#     # Calculate volatility (standard deviation of sentiment) per service\n",
    "#     # Need sufficient data points per service to calculate std dev\n",
    "#     if not avg_sentiment_per_day_month.empty:\n",
    "#         # Calculate std dev of daily average sentiment for each service across all days/months\n",
    "#         sentiment_volatility = avg_sentiment_per_day_month.groupby('service')['sentiment'].std()\n",
    "#         # Drop NaNs that occur if a service has only one data point (std dev is NaN)\n",
    "#         sentiment_volatility = sentiment_volatility.dropna().sort_values(ascending=False)\n",
    "\n",
    "#         # Divide services into three groups based on volatility\n",
    "#         n_services_with_volatility = len(sentiment_volatility)\n",
    "#         if n_services_with_volatility >= 3: # Need at least 3 services to split into 3 groups\n",
    "#              third = n_services_with_volatility // 3\n",
    "#              high_volatility_services = sentiment_volatility.index[:third].tolist()\n",
    "#              medium_volatility_services = sentiment_volatility.index[third:2*third].tolist()\n",
    "#              low_volatility_services = sentiment_volatility.index[2*third:].tolist()\n",
    "#         elif n_services_with_volatility > 0:\n",
    "#              # Handle cases with less than 3 services that have calculated volatility\n",
    "#              print(f\"Warning: Only {n_services_with_volatility} services have enough data for volatility calculation.\")\n",
    "#              if n_services_with_volatility == 2:\n",
    "#                   high_volatility_services = [sentiment_volatility.index[0]]\n",
    "#                   medium_volatility_services = [sentiment_volatility.index[1]]\n",
    "#                   low_volatility_services = []\n",
    "#              elif n_services_with_volatility == 1:\n",
    "#                   high_volatility_services = [sentiment_volatility.index[0]]\n",
    "#                   medium_volatility_services = []\n",
    "#                   low_volatility_services = []\n",
    "#              else: # n_services_with_volatility == 0\n",
    "#                   high_volatility_services = []\n",
    "#                   medium_volatility_services = []\n",
    "#                   low_volatility_services = []\n",
    "#         else:\n",
    "#              print(\"No services have enough data for volatility calculation.\")\n",
    "#              high_volatility_services = []\n",
    "#              medium_volatility_services = []\n",
    "#              low_volatility_services = []\n",
    "\n",
    "#         volatility_groups = {\n",
    "#             \"High Volatility\": high_volatility_services,\n",
    "#             \"Medium Volatility\": medium_volatility_services,\n",
    "#             \"Low Volatility\": low_volatility_services\n",
    "#         }\n",
    "\n",
    "#         # --- Plotting 3x12 Grid by Volatility and Month ---\n",
    "#         # 3 rows (Volatility) x 12 columns (Months) = 36 subplots\n",
    "#         fig, axes = plt.subplots(3, 12, figsize=(30, 12), sharey=True) # Increased overall figure size\n",
    "#         fig.suptitle(\"Average Daily Sentiment per Service by Volatility and Month\", fontsize=16, y=1.03) # Main title\n",
    "\n",
    "#         volatility_level_names = [\"High Volatility\", \"Medium Volatility\", \"Low Volatility\"]\n",
    "\n",
    "#         # Create a single color cycle for all services across all plots\n",
    "#         all_services_colors = cycle(plt.cm.tab10.colors)\n",
    "#         # Map each service to a consistent color\n",
    "#         service_color_map = {service: next(all_services_colors) for service in services}\n",
    "\n",
    "\n",
    "#         # Wrap the loop iterating through volatility groups\n",
    "#         for row_idx, (level_name, services_in_level) in tqdm(enumerate(volatility_groups.items()), total=3, desc=\"Plotting Volatility Levels\"):\n",
    "\n",
    "#             # Wrap the loop iterating through months (columns)\n",
    "#             for month_idx, month_num in tqdm(enumerate(range(1, 13)), total=12, leave=False, desc=f\" Plotting {level_name}\"):\n",
    "#                 ax = axes[row_idx, month_idx] # Get the correct subplot axes\n",
    "\n",
    "#                 month_name = calendar.month_name[month_num]\n",
    "\n",
    "#                 # Filter data for the current month and services in this volatility level\n",
    "#                 monthly_level_data = avg_sentiment_per_day_month[\n",
    "#                     (avg_sentiment_per_day_month['month'] == month_num) &\n",
    "#                     (avg_sentiment_per_day_month['service'].isin(services_in_level))\n",
    "#                 ].copy()\n",
    "\n",
    "#                 if not monthly_level_data.empty:\n",
    "#                      # Plot sentiment for each service within this subplot\n",
    "#                      for service in services_in_level:\n",
    "#                          service_monthly_data = monthly_level_data[monthly_level_data['service'] == service]\n",
    "#                          if not service_monthly_data.empty:\n",
    "#                              color = service_color_map.get(service, 'gray') # Get consistent color, default to gray\n",
    "#                              ax.plot(\n",
    "#                                  service_monthly_data['day'],\n",
    "#                                  service_monthly_data['sentiment'],\n",
    "#                                  label=service,\n",
    "#                                  color=color,\n",
    "#                                  marker='o',\n",
    "#                                  linestyle='-'\n",
    "#                              )\n",
    "\n",
    "#                 # --- Format the subplot ---\n",
    "#                 # Add month name as column title (only for top row)\n",
    "#                 if row_idx == 0:\n",
    "#                     ax.set_title(month_name)\n",
    "\n",
    "#                 # Add volatility level name as row title (only for first column)\n",
    "#                 if month_idx == 0:\n",
    "#                     ax.set_ylabel(level_name) # Use volatility level name as y-label/row title\n",
    "\n",
    "#                 ax.grid(True, axis='y', linestyle='--') # Add horizontal grid\n",
    "\n",
    "#                 # Set x-axis ticks and limits for days\n",
    "#                 ax.set_xticks(range(0, 32, 5))\n",
    "#                 ax.set_xlim(0, 31)\n",
    "\n",
    "#                 # Only show x-axis labels for the bottom row (Low Volatility)\n",
    "#                 if row_idx != 2:\n",
    "#                     ax.tick_params(labelbottom=False)\n",
    "#                 else:\n",
    "#                      ax.set_xlabel(\"Day of Month\") # X-label only on bottom row\n",
    "\n",
    "#                 # Hide y-axis labels for columns after the first one\n",
    "#                 if month_idx != 0:\n",
    "#                     ax.tick_params(labelleft=False)\n",
    "\n",
    "\n",
    "#         # --- Add a single legend for all subplots outside the figure ---\n",
    "#         # Use the service_color_map to create handles for the legend\n",
    "#         legend_handles = [plt.Line2D([0], [0], color=service_color_map.get(service, 'gray'), lw=2) for service in services]\n",
    "#         # Place the legend on the right side of the figure\n",
    "#         fig.legend(legend_handles, services, title=\"Entity\", bbox_to_anchor=(1.02, 0.5), loc='center left', borderaxespad=0.)\n",
    "\n",
    "\n",
    "#         # --- Adjust layout ---\n",
    "#         # Use tight_layout to automatically adjust subplot parameters\n",
    "#         # rect parameter leaves space for the main title and the outside legend\n",
    "#         plt.tight_layout(rect=[0, 0.03, 0.95, 0.98])\n",
    "\n",
    "\n",
    "#         # --- Save the entire figure ---\n",
    "#         # Ensure plot_output_directory is defined and exists before saving\n",
    "#         # Example check: if 'plot_output_directory' in locals() and os.path.exists(plot_output_directory):\n",
    "#         plot_filename = os.path.join(plot_output_directory, \"sentiment_volatility_month_grid.png\")\n",
    "#         plt.savefig(plot_filename)\n",
    "#         plt.close(fig)\n",
    "\n",
    "#         print(f\"3x12 grid plot saved to: {plot_filename}\")\n",
    "\n",
    "#     else:\n",
    "#         print(\"No services have enough data for volatility calculation or daily average calculation failed.\")\n",
    "\n",
    "# else:\n",
    "#     print(\"Post sentiment DataFrame is empty after initial processing. No plots or aggregations performed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213c89f2ecb24a00ab784602e6379fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Plotting Data:   0%|          | 0/3595301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ff1756366f42ee8452965a9bdbf0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Monthly Plots:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4684/3657662659.py:272: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.95, 0.98])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested 3x12 grid plot saved to: YEAR_APPEND/batch_MULTI_PLOT/PLOTS/sentiment_nested_volatility_month_plots.png\n"
     ]
    }
   ],
   "source": [
    "# #4x3 w/ subplots\n",
    "# import pandas as pd\n",
    "# import ast\n",
    "# import matplotlib.pyplot as plt\n",
    "# from itertools import cycle\n",
    "# import os\n",
    "# import calendar\n",
    "# from tqdm.notebook import tqdm\n",
    "# import numpy as np\n",
    "# import matplotlib.gridspec as gridspec # Import gridspec\n",
    "\n",
    "# # Assuming combined_df is already loaded with necessary columns (timestamp, entities, sentiment)\n",
    "# # Assuming 'services' and 'plot_output_directory' are defined\n",
    "\n",
    "# # --- Configuration ---\n",
    "# # Assuming your DataFrame is named 'combined_df' and has the specified columns.\n",
    "# # Assuming 'services' and 'plot_output_directory' are defined.\n",
    "\n",
    "# # Example definitions if they are not defined elsewhere:\n",
    "# # services = [\n",
    "# #     \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "# #     \"ER\", \"Youtube\", \"Reddit\", \"Netflix\",\n",
    "# #     \"Xfinity\", \"Amtrak\", \"Septa\", \"Spirit\", \"American\",\n",
    "# #     \"Disney\"\n",
    "# # ]\n",
    "\n",
    "# # Define your plot output directory\n",
    "# # special_identifier = \"_your_identifier\" # Example, replace with your value\n",
    "# # plot_output_directory = f\"batch{special_identifier}/PLOTS\"\n",
    "# # os.makedirs(plot_output_directory, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "\n",
    "# # --- Extract relevant data and calculate daily average sentiment ---\n",
    "# entity_sentiments_over_time = []\n",
    "\n",
    "# # Assuming combined_df has: timestamp, entities, sentiment\n",
    "# for index, row in tqdm(combined_df.iterrows(), total=len(combined_df), desc=\"Extracting Plotting Data\"):\n",
    "#     try:\n",
    "#         entities_value = row['entities']\n",
    "#         # Handle empty, NaN, or invalid entities\n",
    "#         if pd.isna(entities_value) or entities_value is None or str(entities_value).strip() == \"\":\n",
    "#             ents = []\n",
    "#         else:\n",
    "#             entities_str = str(entities_value)\n",
    "#             try:\n",
    "#                 ents = ast.literal_eval(entities_str)\n",
    "#                 if not isinstance(ents, list):\n",
    "#                      print(f\"Warning: ast.literal_eval did not return a list for row {index}. Result type: {type(ents)}. Value: {entities_value}\")\n",
    "#                      ents = []\n",
    "#             except (SyntaxError, ValueError, Exception) as e:\n",
    "#                 print(f\"Error evaluating entities string for row {index}: {e}. Value: {entities_value}\")\n",
    "#                 ents = []\n",
    "\n",
    "#         # Convert timestamp to datetime and then extract date\n",
    "#         # Assuming 'timestamp' is a timestamp (integer or float)\n",
    "#         if pd.isna(row['timestamp']) or row['timestamp'] is None:\n",
    "#             post_date = None # Handle missing timestamp\n",
    "#         else:\n",
    "#             try:\n",
    "#                 timestamp_numeric = pd.to_numeric(row['timestamp'], errors='coerce')\n",
    "#                 if not pd.isna(timestamp_numeric):\n",
    "#                     post_date = pd.to_datetime(timestamp_numeric, unit='s').date() # Adjust unit if needed\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Could not convert timestamp to numeric for row {index}: {row['timestamp']}\")\n",
    "#                     post_date = None\n",
    "#             except (ValueError, TypeError) as e:\n",
    "#                  print(f\"Error converting timestamp {row['timestamp']} on row {index}: {e}\")\n",
    "#                  post_date = None # Handle invalid timestamp\n",
    "\n",
    "\n",
    "#         sentiment = row['sentiment'] # Assuming sentiment is already a number or NaN\n",
    "\n",
    "#         if post_date is not None: # Only process if date is valid\n",
    "#              for ent_text, ent_label in ents:\n",
    "#                  if isinstance(ent_text, str) and isinstance(ent_label, str) and ent_label == 'SERVICE' and ent_text in services:\n",
    "#                     if np.isreal(sentiment): # Corrected: Use np.isreal\n",
    "#                         entity_sentiments_over_time.append((ent_text, post_date, float(sentiment))) # Ensure sentiment is float\n",
    "#                     else:\n",
    "#                          print(f\"Warning: Skipping non-numeric sentiment {sentiment} for row {index}.\")\n",
    "\n",
    "\n",
    "#     except (KeyError, TypeError, Exception) as e:\n",
    "#         print(f\"Error processing row {index}: {e}\")\n",
    "#         continue\n",
    "\n",
    "\n",
    "# # Create a DataFrame from the extracted data\n",
    "# entity_sentiment_df = pd.DataFrame(entity_sentiments_over_time, columns=['service', 'date', 'sentiment'])\n",
    "\n",
    "# # Convert the 'date' column to datetime objects and extract month and day\n",
    "# if not entity_sentiment_df.empty:\n",
    "#     if not pd.api.types.is_datetime64_any_dtype(entity_sentiment_df['date']):\n",
    "#          try:\n",
    "#              entity_sentiment_df['date'] = pd.to_datetime(entity_sentiment_df['date'])\n",
    "#          except ValueError as e:\n",
    "#               print(f\"Error converting 'date' column to datetime: {e}\")\n",
    "#               print(\"Please ensure the 'date' column is in a recognizable format.\")\n",
    "#               entity_sentiment_df = pd.DataFrame() # Clear if date conversion fails\n",
    "\n",
    "# if not entity_sentiment_df.empty:\n",
    "#     entity_sentiment_df['month'] = entity_sentiment_df['date'].dt.month\n",
    "#     entity_sentiment_df['day'] = entity_sentiment_df['date'].dt.day\n",
    "\n",
    "#     # Calculate daily average sentiment\n",
    "#     if all(col in entity_sentiment_df.columns for col in ['service', 'month', 'day', 'sentiment']):\n",
    "#          # Group by service, month, and day to get daily average within each month\n",
    "#          avg_sentiment_per_day_month = entity_sentiment_df.groupby(['service', 'month', 'day'])['sentiment'].mean().reset_index()\n",
    "#     else:\n",
    "#          print(\"Required columns for daily average grouping ('service', 'month', 'day', 'sentiment') not found after extraction.\")\n",
    "#          avg_sentiment_per_day_month = pd.DataFrame() # Ensure it's an empty DataFrame\n",
    "\n",
    "\n",
    "#     # Calculate volatility (standard deviation of sentiment) per service\n",
    "#     # Need sufficient data points per service to calculate std dev\n",
    "#     if not avg_sentiment_per_day_month.empty:\n",
    "#         # Calculate std dev of daily average sentiment for each service across all days/months\n",
    "#         sentiment_volatility = avg_sentiment_per_day_month.groupby('service')['sentiment'].std()\n",
    "#         # Drop NaNs that occur if a service has only one data point (std dev is NaN)\n",
    "#         sentiment_volatility = sentiment_volatility.dropna().sort_values(ascending=False)\n",
    "\n",
    "#         # Divide services into three groups based on volatility\n",
    "#         n_services_with_volatility = len(sentiment_volatility)\n",
    "#         if n_services_with_volatility >= 3: # Need at least 3 services to split into 3 groups\n",
    "#              third = n_services_with_volatility // 3\n",
    "#              high_volatility_services = sentiment_volatility.index[:third].tolist()\n",
    "#              medium_volatility_services = sentiment_volatility.index[third:2*third].tolist()\n",
    "#              low_volatility_services = sentiment_volatility.index[2*third:].tolist()\n",
    "#         elif n_services_with_volatility > 0:\n",
    "#              # Handle cases with less than 3 services that have calculated volatility\n",
    "#              print(f\"Warning: Only {n_services_with_volatility} services have enough data for volatility calculation.\")\n",
    "#              if n_services_with_volatility == 2:\n",
    "#                   high_volatility_services = [sentiment_volatility.index[0]]\n",
    "#                   medium_volatility_services = [sentiment_volatility.index[1]]\n",
    "#                   low_volatility_services = []\n",
    "#              elif n_services_with_volatility == 1:\n",
    "#                   high_volatility_services = [sentiment_volatility.index[0]]\n",
    "#                   medium_volatility_services = []\n",
    "#                   low_volatility_services = []\n",
    "#              else: # n_services_with_volatility == 0\n",
    "#                   high_volatility_services = []\n",
    "#                   medium_volatility_services = []\n",
    "#                   low_volatility_services = []\n",
    "#         else:\n",
    "#              print(\"No services have enough data for volatility calculation.\")\n",
    "#              high_volatility_services = []\n",
    "#              medium_volatility_services = []\n",
    "#              low_volatility_services = []\n",
    "\n",
    "#         volatility_groups = {\n",
    "#             \"High Volatility\": high_volatility_services,\n",
    "#             \"Medium Volatility\": medium_volatility_services,\n",
    "#             \"Low Volatility\": low_volatility_services\n",
    "#         }\n",
    "\n",
    "#         # --- Plotting Sentiment vs. Date with Nested Subplots (4x3 Monthly Grid, 3 Volatility Rows per Month) ---\n",
    "#         fig = plt.figure(figsize=(20, 20)) # Adjust overall figure size\n",
    "\n",
    "#         # Create a main grid for the months (4 rows, 3 columns)\n",
    "#         # Adjust wspace and hspace to control spacing between month blocks\n",
    "#         outer_grid = gridspec.GridSpec(4, 3, wspace=0.2, hspace=0.3)\n",
    "\n",
    "#         # Create a single color cycle for all services across all plots\n",
    "#         all_services_colors = cycle(plt.cm.tab10.colors)\n",
    "#         # Map each service to a consistent color\n",
    "#         service_color_map = {service: next(all_services_colors) for service in services}\n",
    "\n",
    "#         # Wrap the loop iterating through months (outer grid cells)\n",
    "#         for month_idx, month_num in tqdm(enumerate(range(1, 13)), total=12, desc=\"Generating Monthly Plots\"):\n",
    "#             month_name = calendar.month_name[month_num]\n",
    "#             row_idx = month_idx // 3 # Determine the row in the outer grid (0-3)\n",
    "#             col_idx = month_idx % 3  # Determine the column in the outer grid (0-2)\n",
    "\n",
    "#             # Create a subgrid within the current outer grid cell (3 rows for volatility, 1 column)\n",
    "#             # Adjust hspace to control vertical spacing between inner plots for this month\n",
    "#             inner_grid = gridspec.GridSpecFromSubplotSpec(3, 1,\n",
    "#                                                           subplot_spec=outer_grid[row_idx, col_idx],\n",
    "#                                                           hspace=0.05) # Minimal vertical spacing between inner plots\n",
    "\n",
    "#             # Filter data for the current month\n",
    "#             monthly_data = avg_sentiment_per_day_month[avg_sentiment_per_day_month['month'] == month_num].copy()\n",
    "\n",
    "\n",
    "#             volatility_level_names = [\"High Volatility\", \"Medium Volatility\", \"Low Volatility\"]\n",
    "\n",
    "#             # Create a list to hold the axes for sharing the y-axis within the inner grid\n",
    "#             inner_axes = []\n",
    "\n",
    "#             # Wrap the loop iterating through volatility levels within the month\n",
    "#             for inner_row_idx, level_name in enumerate(volatility_level_names):\n",
    "#                 services_in_level = volatility_groups.get(level_name, []) # Get the services for this volatility level\n",
    "\n",
    "\n",
    "#                 # Get the subplot axes for the current volatility level within the inner grid\n",
    "#                 # Share y-axis among the three plots within this month's block\n",
    "#                 if inner_row_idx == 0: # First inner plot (High Volatility)\n",
    "#                      ax = fig.add_subplot(inner_grid[inner_row_idx, 0])\n",
    "#                 else: # Subsequent inner plots - share y-axis with the first inner plot in this cell\n",
    "#                      ax = fig.add_subplot(inner_grid[inner_row_idx, 0], sharey=inner_axes[0])\n",
    "\n",
    "#                 inner_axes.append(ax) # Add the current axes to the list\n",
    "\n",
    "#                 # Filter data for services in this volatility level for the current month\n",
    "#                 # Need to ensure services_in_level is not empty before filtering\n",
    "#                 if services_in_level:\n",
    "#                      monthly_level_data = monthly_data[\n",
    "#                          monthly_data['service'].isin(services_in_level)\n",
    "#                      ].copy()\n",
    "#                 else:\n",
    "#                      monthly_level_data = pd.DataFrame() # Empty DataFrame if no services in level\n",
    "\n",
    "\n",
    "#                 if not monthly_level_data.empty:\n",
    "#                      # Plot sentiment for each service within this inner subplot\n",
    "#                      for service in services_in_level:\n",
    "#                          service_monthly_data = monthly_level_data[monthly_level_data['service'] == service]\n",
    "#                          if not service_monthly_data.empty:\n",
    "#                              color = service_color_map.get(service, 'gray') # Get consistent color, default to gray\n",
    "#                              ax.plot(\n",
    "#                                  service_monthly_data['day'],\n",
    "#                                  service_monthly_data['sentiment'],\n",
    "#                                  label=service,\n",
    "#                                  color=color,\n",
    "#                                  marker='o',\n",
    "#                                  linestyle='-'\n",
    "#                              )\n",
    "\n",
    "#                 # --- Format the inner subplot ---\n",
    "#                 ax.grid(True, axis='y', linestyle='--') # Add horizontal grid\n",
    "\n",
    "#                 # Set x-axis ticks and limits for days\n",
    "#                 ax.set_xticks(range(0, 32, 5))\n",
    "#                 ax.set_xlim(0, 31)\n",
    "\n",
    "#                 # Set title for the month (only on the top inner subplot)\n",
    "#                 if inner_row_idx == 0:\n",
    "#                     ax.set_title(month_name)\n",
    "#                     # Add y-label for the first column's top inner plot\n",
    "#                     if col_idx == 0:\n",
    "#                          ax.set_ylabel(\"Avg Sentiment\")\n",
    "#                 else:\n",
    "#                     # Hide x-axis labels for inner plots that are not at the bottom of the inner grid\n",
    "#                      ax.tick_params(labelbottom=False)\n",
    "\n",
    "\n",
    "#                 # Only show y-axis labels for the first column of outer grid\n",
    "#                 if col_idx != 0:\n",
    "#                      ax.tick_params(labelleft=False)\n",
    "\n",
    "#                 # Add volatility level name as text annotation on the right side of the inner plots\n",
    "#                 # You might need to adjust the coordinates (1.02, 0.5) and text alignment based on figsize\n",
    "#                 # This is an alternative to row titles on the left\n",
    "#                 ax.text(1.02, 0.5, level_name, transform=ax.transAxes,\n",
    "#                         fontsize=9, va='center', ha='left', rotation=0)\n",
    "\n",
    "\n",
    "#             # Set a common x-label for the inner grid (only on the bottom inner plot)\n",
    "#             # This will be plotted *below* the bottom inner plot\n",
    "#             inner_axes[-1].set_xlabel(\"Day of Month\")\n",
    "\n",
    "\n",
    "#     # --- Add a single legend for all subplots outside the figure ---\n",
    "#     # Use the service_color_map to create handles for the legend\n",
    "#     legend_handles = [plt.Line2D([0], [0], color=service_color_map.get(service, 'gray'), lw=2) for service in services]\n",
    "#     # Place the legend on the right side of the figure\n",
    "#     fig.legend(legend_handles, services, title=\"Entity\", bbox_to_anchor=(1.02, 0.5), loc='center left', borderaxespad=0.)\n",
    "\n",
    "\n",
    "#     # --- Adjust layout ---\n",
    "#     # Use tight_layout on the figure\n",
    "#     # rect parameter leaves space for the main title and the outside legend\n",
    "#     # Adjust rect based on overall figsize and legend position\n",
    "#     plt.tight_layout(rect=[0, 0.03, 0.95, 0.98])\n",
    "\n",
    "\n",
    "#     # --- Save the entire figure ---\n",
    "#     # Ensure plot_output_directory is defined and exists before saving\n",
    "#     # Example check: if 'plot_output_directory' in locals() and os.path.exists(plot_output_directory):\n",
    "#     plot_filename = os.path.join(plot_output_directory, \"sentiment_nested_volatility_month_plots.png\")\n",
    "#     plt.savefig(plot_filename)\n",
    "#     plt.close(fig)\n",
    "\n",
    "#     print(f\"Nested 3x12 grid plot saved to: {plot_filename}\")\n",
    "\n",
    "# else:\n",
    "#     print(\"Average daily sentiment DataFrame is empty after aggregation or no services have calculated volatility.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7348bac7d6d841eeb64fbce2d56850a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Plotting Data:   0%|          | 0/3595301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8898e53c3744549bae386905aae6e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Monthly Plots:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4684/1681653069.py:271: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 0.90, 0.98])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested 3x12 grid plot saved to: YEAR_APPEND/batch_MULTI_PLOT/PLOTS/sentiment_nested_volatility_month_plots.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import os\n",
    "import calendar\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Assuming combined_df is already loaded with necessary columns\n",
    "# Assuming 'services' and 'plot_output_directory' are defined\n",
    "\n",
    "# --- Configuration ---\n",
    "# Assuming your DataFrame is named 'combined_df' and has the specified columns.\n",
    "# Assuming 'services' and 'plot_output_directory' are defined.\n",
    "\n",
    "# Example definitions if they are not defined elsewhere:\n",
    "# services = [\n",
    "#     \"Comcast\", \"Airline\", \"Healthcare\", \"Trains\", \"Banks\", \"United States\",\n",
    "#     \"ER\", \"Youtube\", \"Reddit\", \"Netflix\",\n",
    "#     \"Xfinity\", \"Amtrak\", \"Septa\", \"Spirit\", \"American\",\n",
    "#     \"Disney\"\n",
    "# ]\n",
    "\n",
    "# Define your plot output directory\n",
    "# special_identifier = \"_your_identifier\" # Example, replace with your value\n",
    "# plot_output_directory = f\"batch{special_identifier}/PLOTS\"\n",
    "# os.makedirs(plot_output_directory, exist_ok=True) # Ensure directory exists\n",
    "\n",
    "\n",
    "# --- Extract relevant data and calculate daily average sentiment ---\n",
    "entity_sentiments_over_time = []\n",
    "\n",
    "# Assuming combined_df has: timestamp, entities, sentiment\n",
    "for index, row in tqdm(combined_df.iterrows(), total=len(combined_df), desc=\"Extracting Plotting Data\"):\n",
    "    try:\n",
    "        entities_value = row['entities']\n",
    "        # Handle empty, NaN, or invalid entities\n",
    "        if pd.isna(entities_value) or entities_value is None or str(entities_value).strip() == \"\":\n",
    "            ents = []\n",
    "        else:\n",
    "            entities_str = str(entities_value)\n",
    "            try:\n",
    "                ents = ast.literal_eval(entities_str)\n",
    "                if not isinstance(ents, list):\n",
    "                     print(f\"Warning: ast.literal_eval did not return a list for row {index}. Result type: {type(ents)}. Value: {entities_value}\")\n",
    "                     ents = []\n",
    "            except (SyntaxError, ValueError, Exception) as e:\n",
    "                print(f\"Error evaluating entities string for row {index}: {e}. Value: {entities_value}\")\n",
    "                ents = []\n",
    "\n",
    "        # Convert timestamp to datetime and then extract date\n",
    "        # Assuming 'timestamp' is a timestamp (integer or float)\n",
    "        if pd.isna(row['timestamp']) or row['timestamp'] is None:\n",
    "            post_date = None # Handle missing timestamp\n",
    "        else:\n",
    "            try:\n",
    "                timestamp_numeric = pd.to_numeric(row['timestamp'], errors='coerce')\n",
    "                if not pd.isna(timestamp_numeric):\n",
    "                    post_date = pd.to_datetime(timestamp_numeric, unit='s').date() # Adjust unit if needed\n",
    "                else:\n",
    "                    print(f\"Warning: Could not convert timestamp to numeric for row {index}: {row['timestamp']}\")\n",
    "                    post_date = None\n",
    "            except (ValueError, TypeError) as e:\n",
    "                 print(f\"Error converting timestamp {row['timestamp']} on row {index}: {e}\")\n",
    "                 post_date = None # Handle invalid timestamp\n",
    "\n",
    "\n",
    "        sentiment = row['sentiment'] # Assuming sentiment is already a number or NaN\n",
    "\n",
    "        if post_date is not None: # Only process if date is valid\n",
    "             for ent_text, ent_label in ents:\n",
    "                 if isinstance(ent_text, str) and isinstance(ent_label, str) and ent_label == 'SERVICE' and ent_text in services:\n",
    "                    if np.isreal(sentiment): # Corrected: Use np.isreal\n",
    "                        entity_sentiments_over_time.append((ent_text, post_date, float(sentiment))) # Ensure sentiment is float\n",
    "                    else:\n",
    "                         print(f\"Warning: Skipping non-numeric sentiment {sentiment} for row {index}.\")\n",
    "\n",
    "\n",
    "    except (KeyError, TypeError, Exception) as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "entity_sentiment_df = pd.DataFrame(entity_sentiments_over_time, columns=['service', 'date', 'sentiment'])\n",
    "\n",
    "# Convert the 'date' column to datetime objects and extract month and day\n",
    "if not entity_sentiment_df.empty:\n",
    "    if not pd.api.types.is_datetime64_any_dtype(entity_sentiment_df['date']):\n",
    "         try:\n",
    "             entity_sentiment_df['date'] = pd.to_datetime(entity_sentiment_df['date'])\n",
    "         except ValueError as e:\n",
    "              print(f\"Error converting 'date' column to datetime: {e}\")\n",
    "              print(\"Please ensure the 'date' column is in a recognizable format.\")\n",
    "              entity_sentiment_df = pd.DataFrame() # Clear if date conversion fails\n",
    "\n",
    "if not entity_sentiment_df.empty:\n",
    "    entity_sentiment_df['month'] = entity_sentiment_df['date'].dt.month\n",
    "    entity_sentiment_df['day'] = entity_sentiment_df['date'].dt.day\n",
    "\n",
    "    # Calculate daily average sentiment\n",
    "    if all(col in entity_sentiment_df.columns for col in ['service', 'month', 'day', 'sentiment']):\n",
    "         # Group by service, month, and day to get daily average within each month\n",
    "         avg_sentiment_per_day_month = entity_sentiment_df.groupby(['service', 'month', 'day'])['sentiment'].mean().reset_index()\n",
    "    else:\n",
    "         print(\"Required columns for daily average grouping ('service', 'month', 'day', 'sentiment') not found after extraction.\")\n",
    "         avg_sentiment_per_day_month = pd.DataFrame() # Ensure it's an empty DataFrame\n",
    "\n",
    "\n",
    "    # Calculate volatility (standard deviation of sentiment) per service\n",
    "    # Need sufficient data points per service to calculate std dev\n",
    "    if not avg_sentiment_per_day_month.empty:\n",
    "        # Calculate std dev of daily average sentiment for each service across all days/months\n",
    "        sentiment_volatility = avg_sentiment_per_day_month.groupby('service')['sentiment'].std()\n",
    "        # Drop NaNs that occur if a service has only one data point (std dev is NaN)\n",
    "        sentiment_volatility = sentiment_volatility.dropna().sort_values(ascending=False)\n",
    "\n",
    "        # Divide services into three groups based on volatility\n",
    "        n_services_with_volatility = len(sentiment_volatility)\n",
    "        if n_services_with_volatility >= 3: # Need at least 3 services to split into 3 groups\n",
    "             third = n_services_with_volatility // 3\n",
    "             high_volatility_services = sentiment_volatility.index[:third].tolist()\n",
    "             medium_volatility_services = sentiment_volatility.index[third:2*third].tolist()\n",
    "             low_volatility_services = sentiment_volatility.index[2*third:].tolist()\n",
    "        elif n_services_with_volatility > 0:\n",
    "             # Handle cases with less than 3 services that have calculated volatility\n",
    "             print(f\"Warning: Only {n_services_with_volatility} services have enough data for volatility calculation.\")\n",
    "             if n_services_with_volatility == 2:\n",
    "                  high_volatility_services = [sentiment_volatility.index[0]]\n",
    "                  medium_volatility_services = [sentiment_volatility.index[1]]\n",
    "                  low_volatility_services = []\n",
    "             elif n_services_with_volatility == 1:\n",
    "                  high_volatility_services = [sentiment_volatility.index[0]]\n",
    "                  medium_volatility_services = []\n",
    "                  low_volatility_services = []\n",
    "             else: # n_services_with_volatility == 0\n",
    "                  high_volatility_services = []\n",
    "                  medium_volatility_services = []\n",
    "                  low_volatility_services = []\n",
    "        else:\n",
    "             print(\"No services have enough data for volatility calculation.\")\n",
    "             high_volatility_services = []\n",
    "             medium_volatility_services = []\n",
    "             low_volatility_services = []\n",
    "\n",
    "        volatility_groups = {\n",
    "            \"High Volatility\": high_volatility_services,\n",
    "            \"Medium Volatility\": medium_volatility_services,\n",
    "            \"Low Volatility\": low_volatility_services\n",
    "        }\n",
    "\n",
    "        # --- Plotting Sentiment vs. Date with Nested Subplots (4x3 Monthly Grid, 3 Volatility Rows per Month) ---\n",
    "        # Increased figure width to provide more space for the legend\n",
    "        fig = plt.figure(figsize=(22, 20))\n",
    "\n",
    "        # Create a main grid for the months (4 rows, 3 columns)\n",
    "        # Adjust wspace and hspace\n",
    "        outer_grid = gridspec.GridSpec(4, 3, wspace=0.2, hspace=0.3)\n",
    "\n",
    "        # Create a single color cycle for all services across all plots\n",
    "        all_services_colors = cycle(plt.cm.tab10.colors)\n",
    "        # Map each service to a consistent color\n",
    "        service_color_map = {service: next(all_services_colors) for service in services}\n",
    "\n",
    "        # Wrap the loop iterating through months (outer grid cells)\n",
    "        for month_idx, month_num in tqdm(enumerate(range(1, 13)), total=12, desc=\"Generating Monthly Plots\"):\n",
    "            month_name = calendar.month_name[month_num]\n",
    "            row_idx = month_idx // 3 # Determine the row in the outer grid (0-3)\n",
    "            col_idx = month_idx % 3  # Determine the column in the outer grid (0-2)\n",
    "\n",
    "            # Create a subgrid within the current outer grid cell (3 rows for volatility, 1 column)\n",
    "            # Adjust hspace\n",
    "            inner_grid = gridspec.GridSpecFromSubplotSpec(3, 1,\n",
    "                                                          subplot_spec=outer_grid[row_idx, col_idx],\n",
    "                                                          hspace=0.05) # Minimal vertical spacing\n",
    "\n",
    "            # Filter data for the current month\n",
    "            monthly_data = avg_sentiment_per_day_month[avg_sentiment_per_day_month['month'] == month_num].copy()\n",
    "\n",
    "\n",
    "            volatility_level_names = [\"High Volatility\", \"Medium Volatility\", \"Low Volatility\"]\n",
    "\n",
    "            # Create a list to hold the axes for sharing the y-axis within the inner grid\n",
    "            inner_axes = []\n",
    "\n",
    "            # Wrap the loop iterating through volatility levels within the month\n",
    "            for inner_row_idx, level_name in enumerate(volatility_level_names):\n",
    "                services_in_level = volatility_groups.get(level_name, []) # Get the services for this volatility level\n",
    "\n",
    "\n",
    "                # Get the subplot axes for the current volatility level within the inner grid\n",
    "                # Share y-axis among the three plots within this month's block\n",
    "                if inner_row_idx == 0: # First inner plot (High Volatility)\n",
    "                     ax = fig.add_subplot(inner_grid[inner_row_idx, 0])\n",
    "                else: # Subsequent inner plots - share y-axis with the first inner plot in this cell\n",
    "                     ax = fig.add_subplot(inner_grid[inner_row_idx, 0], sharey=inner_axes[0])\n",
    "\n",
    "                inner_axes.append(ax) # Add the current axes to the list\n",
    "\n",
    "                # Filter data for services in this volatility level for the current month\n",
    "                if services_in_level:\n",
    "                     monthly_level_data = monthly_data[\n",
    "                         monthly_data['service'].isin(services_in_level)\n",
    "                     ].copy()\n",
    "                else:\n",
    "                     monthly_level_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "                if not monthly_level_data.empty:\n",
    "                     # Plot sentiment for each service within this inner subplot\n",
    "                     for service in services_in_level:\n",
    "                         service_monthly_data = monthly_level_data[monthly_level_data['service'] == service]\n",
    "                         if not service_monthly_data.empty:\n",
    "                             color = service_color_map.get(service, 'gray') # Get consistent color\n",
    "                             # --- Removed marker='o' to remove points ---\n",
    "                             ax.plot(\n",
    "                                 service_monthly_data['day'],\n",
    "                                 service_monthly_data['sentiment'],\n",
    "                                 label=service,\n",
    "                                 color=color,\n",
    "                                 linestyle='-' # Use a line to connect daily points\n",
    "                             )\n",
    "\n",
    "                # --- Format the inner subplot ---\n",
    "                ax.grid(True, axis='y', linestyle='--') # Add horizontal grid\n",
    "\n",
    "                # Set x-axis ticks and limits for days\n",
    "                ax.set_xticks(range(0, 32, 5))\n",
    "                ax.set_xlim(0, 31)\n",
    "\n",
    "                # Set title for the month (only on the top inner subplot)\n",
    "                if inner_row_idx == 0:\n",
    "                    ax.set_title(month_name)\n",
    "                    # Add y-label for the first column's top inner plot\n",
    "                    if col_idx == 0:\n",
    "                         ax.set_ylabel(\"Avg Sentiment\")\n",
    "                else:\n",
    "                    # Hide x-axis labels for inner plots that are not at the bottom of the inner grid\n",
    "                     ax.tick_params(labelbottom=False)\n",
    "\n",
    "\n",
    "                # Only show y-axis labels for the first column of outer grid\n",
    "                if col_idx != 0:\n",
    "                     ax.tick_params(labelleft=False)\n",
    "\n",
    "                # Add volatility level name as text annotation on the right side of the inner plots\n",
    "                # --- Added rotation=90 to rotate text ---\n",
    "                ax.text(1.02, 0.5, level_name, transform=ax.transAxes,\n",
    "                        fontsize=9, va='center', ha='left', rotation=90)\n",
    "\n",
    "\n",
    "            # Set a common x-label for the inner grid (only on the bottom inner plot)\n",
    "            inner_axes[-1].set_xlabel(\"Day of Month\")\n",
    "\n",
    "\n",
    "    # --- Add a single legend for all subplots outside the figure ---\n",
    "    # Use the service_color_map to create handles for the legend\n",
    "    # This legend already existed and shows line colors mapping to services\n",
    "    legend_handles = [plt.Line2D([0], [0], color=service_color_map.get(service, 'gray'), lw=2) for service in services]\n",
    "    # Place the legend on the right side of the figure\n",
    "    # Adjust bbox_to_anchor and rect to ensure legend is visible\n",
    "    fig.legend(legend_handles, services, title=\"Entity\", bbox_to_anchor=(1.02, 0.5), loc='center left', borderaxespad=0.)\n",
    "\n",
    "\n",
    "    # --- Adjust layout ---\n",
    "    # Use tight_layout on the figure\n",
    "    # rect parameter leaves space for the main title and the outside legend\n",
    "    # Adjusted rect right boundary to 0.90 to allow more space for legend\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.90, 0.98])\n",
    "\n",
    "\n",
    "    # --- Save the entire figure ---\n",
    "    plot_filename = os.path.join(plot_output_directory, \"sentiment_nested_volatility_month_plots2.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Nested 3x12 grid plot saved to: {plot_filename}\")\n",
    "\n",
    "else:\n",
    "    print(\"Average daily sentiment DataFrame is empty after aggregation or no services have calculated volatility.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
